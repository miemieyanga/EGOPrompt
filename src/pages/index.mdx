---
layout: ../layouts/Layout.astro
title: How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Structured Knowledge Adaptation
authors:
  - name: "Yang Zhao"
    url: "https://scholar.google.com.hk/citations?user=_Y02L7sAAAAJ"
    institution: "Johns Hopkins University"
  - name: "Pu Wang"
    url: "https://www.linkedin.com/in/pu-wang-a85048389/"
    institution: "Johns Hopkins University"
  - name: "Hao Frank Yang"
    url: "https://www.haofrankyang.net/"
    institution: "Johns Hopkins University"
    notes: ["†"]
conference: NeurIPS 2025
notes:
  - symbol: "†"
    text: Corresponding author
links:
  - name: Paper
    url: https://github.com/
    icon: ri:file-pdf-2-line
  - name: Code
    url: https://github.com/
    icon: ri:github-line
  - name: arXiv
    url: https://github.com/
    icon: academicons:arxiv

# The color theme of the page. Defaults to "device" (the preference set in the user's brower or operating system). Setting this to "light" or "dark" will override the user's preference. This is useful if your figures only look good in one theme.
theme: device

# This is the icon that appears in the user's browser tab. To customize, change the favicon.svg file in /public/, or add your own file to /public/ and change the filename here.
favicon: favicon.svg

# These keys are optional. If a link to your project page is in a Google search result, text message, or social media post, it will often appear as a "link preview card" based on its title, description, favicon, and thumbnail. After you publish your page, you can double check that these previews look right using [this tool](https://linkpreview.xyz/)
description: Ego-Prompt can find better prompts for domain-specific tasks.
thumbnail: screenshot-light.png
---

import Video from "../components/Video.astro";
import HighlightedSection from "../components/HighlightedSection.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Figure from "../components/Figure.astro";
import Picture from "../components/Picture.astro";
import ModelViewer from "../components/ModelViewer.astro";
import TwoColumns from "../components/TwoColumns.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import LaTeX from "../components/LaTeX.astro";
import { Comparison } from "../components/Comparison.tsx";
import Table from "../components/Table.astro";
import main from "../assets/main.png";
export const components = { table: Table };

<HighlightedSection>

## Abstract

Designing optimal prompts and reasoning processes for large language models (LLMs) on domain-specific tasks is both necessary and challenging in real-world applications. Determining how to integrate domain knowledge, enhance reasoning efficiency, and even provide domain experts with refined knowledge integration hints are particularly crucial yet unresolved tasks. In this research, we propose Evolutionary Graph Optimization for Prompting (EGO-Prompt), an automated framework to designing optimal prompts, efficient reasoning processes and providing enhanced causal-informed process. EGO-Prompt begins with an general prompt and fault-tolerant initial Semantic Causal Graph (SCG) descriptions, constructed by human experts, which is then automatically refined and optimized to guide LLM reasoning. Recognizing that expert-defined SCGs may be partial or imperfect and that their optimal integration varies across LLMs, EGO-Prompt integrates a novel causal-guided textual gradient process in two steps: first, generating nearly deterministic reasoning guidance from the SCG for each instance, and second, adapting the LLM to effectively utilize the guidance alongside the original input. The iterative optimization algorithm further refines both the SCG and the reasoning mechanism using textual gradients with ground-truth. We tested the framework on real-world public health, transportation and human behavior tasks and EGO-Prompt demonstrates clear improvements, achieving increases of 7.32%–12.61% in F1 score compared to state-of-the-art methods. Furthermore, EGO-Prompt allows small models to reach reasoning-level performance at over 7× lower cost, together with an interpretable refined domain SCG for enhanced interpretability.

</HighlightedSection>

## Figures


<Figure>
  <Picture slot="figure" src={main} alt="Overview of the proposed EGO-Prompt framework." invertInDarkMode />
  <Fragment slot="caption">Overview of the proposed EGO-Prompt framework. (a) LLMs often struggle with domain-specific tasks due to the optimal prompt design and domain knowledge gap. Existing methods rely on the external database or established graph. In comparison, EGO-Prompt evolutionarily incorporates expert knowledge with minimal cost. (b) We represent external knowledge as a graph-based structure. A graph-enhanced prompt is then generated to guide the LLM’s reasoning. Both the graph and the prompt are iteratively optimized using textual gradients from ground-truth data.</Fragment>
</Figure>


## BibTeX citation

Displaying your BibTeX citation in a code block makes it easy to copy and paste.

```bibtex
@inproceedings{zhao2025how,
  author = "{Yang Zhao, Pu Wang, Hao Frank Yang}",
  title = "How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Structured Knowledge Adaptation",
  booktitle={The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS)},
  year = "2025",
}
```

